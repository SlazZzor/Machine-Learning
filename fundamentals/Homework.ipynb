{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d804d2-8dd3-4e4d-a8b4-1cb94955250e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4116, 0.5669, 0.4611, 0.4767, 0.6993, 0.9830, 0.1307],\n",
       "        [0.0027, 0.2342, 0.4703, 0.0865, 0.0036, 0.5895, 0.7870],\n",
       "        [0.3717, 0.8555, 0.7964, 0.4646, 0.8175, 0.8297, 0.8926],\n",
       "        [0.0724, 0.4737, 0.1734, 0.4421, 0.6611, 0.6302, 0.3769],\n",
       "        [0.2150, 0.4269, 0.3739, 0.5803, 0.9296, 0.4637, 0.9570],\n",
       "        [0.0279, 0.5096, 0.1516, 0.1953, 0.8233, 0.7534, 0.4731],\n",
       "        [0.4433, 0.3361, 0.7818, 0.3536, 0.4530, 0.1425, 0.5521]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with shape (7, 7).\n",
    "import torch\n",
    "tensor = torch.rand(7, 7)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef7d5fcd-d31f-4467-aa62-0adae2c2ad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.0309],\n",
      "        [2.1748],\n",
      "        [1.5700],\n",
      "        [1.4983],\n",
      "        [2.0202],\n",
      "        [2.4908],\n",
      "        [2.4459]])\n"
     ]
    }
   ],
   "source": [
    "# Perform a matrix multiplication on the tensor from 2 \n",
    "# with another random tensor with shape (1, 7) \n",
    "#(hint: you may have to transpose the second tensor).\n",
    "tensor_A = torch.rand(7, 7)\n",
    "tensor_B = torch.rand(1, 7)\n",
    "print(torch.matmul(tensor_A, tensor_B.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff23be5-0e8b-4428-83ed-6aae4cef08a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8542],\n",
      "        [1.9611],\n",
      "        [2.2884],\n",
      "        [3.0481],\n",
      "        [1.7067],\n",
      "        [2.5290],\n",
      "        [1.7989]])\n"
     ]
    }
   ],
   "source": [
    "#Set the random seed to 0 and do exercises 2 & 3 over again.\n",
    "torch.manual_seed(0)\n",
    "tensor_A = torch.rand(7, 7)\n",
    "tensor_B = torch.rand(1, 7)\n",
    "print(torch.matmul(tensor_A, tensor_B.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1c5a011-19c7-4c48-af29-dd6c9de69078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaking of random seeds, we saw how to set it with torch.manual_seed() \n",
    "# but is there a GPU equivalent? \n",
    "# (hint: you'll need to look into the documentation for torch.cuda for this one). \n",
    "# If there is, set the GPU random seed to 1234.\n",
    "torch.cuda.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153e157f-dd54-4289-a006-2856dda24b3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create two random tensors of shape (2, 3) and send them both to the GPU \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# (you'll need access to a GPU for this). \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Set torch.manual_seed(1234) when creating the tensors \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# (this doesn't have to be the GPU random seed).\u001b[39;00m\n\u001b[1;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1234\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(tensor_A, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,tensor_B)\n",
      "File \u001b[0;32m~/Programming/ML/TorchLearning/myenv/lib/python3.10/site-packages/torch/cuda/__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Create two random tensors of shape (2, 3) and send them both to the GPU \n",
    "# (you'll need access to a GPU for this). \n",
    "# Set torch.manual_seed(1234) when creating the tensors \n",
    "# (this doesn't have to be the GPU random seed).\n",
    "torch.cuda.manual_seed(1234)\n",
    "tensor_A = torch.rand(2, 3, device=\"cuda\")\n",
    "tensor_B = torch.rand(2, 3, device=\"cuda\")\n",
    "print(tensor_A, \"\\n\",tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7327f70a-af0c-40ae-87b1-6da77a70e58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8542],\n",
      "        [1.9611],\n",
      "        [2.2884],\n",
      "        [3.0481],\n",
      "        [1.7067],\n",
      "        [2.5290],\n",
      "        [1.7989]])\n"
     ]
    }
   ],
   "source": [
    "# Perform a matrix multiplication on the tensors you created in 6 \n",
    "# (again, you may have to adjust the shapes of one of the tensors).\n",
    "newTensor = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(newTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af56058c-5588-4838-8f3f-9ee850153b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0481)\n",
      "tensor(1.7067)\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum and minimum values of the output of 7.\n",
    "print(newTensor.max())\n",
    "print(newTensor.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40dc82ed-23a7-4df3-8c15-abb9d0acb7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "#Find the maximum and minimum index values of the output of 7.\n",
    "print(newTensor.argmax())\n",
    "print(newTensor.argmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06edd03b-a575-4b0a-9f1e-4fc13426154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a random tensor with shape (1, 1, 1, 10) and \n",
    "# then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). \n",
    "# Set the seed to 7 when you create it and \n",
    "# print out the first tensor and it's shape as well as the second tensor and it's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58969725-7277-43a9-b37f-f768c8d588e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
      "           0.3653, 0.8513]]]])\n",
      "torch.Size([1, 1, 1, 10])\n",
      "--------\n",
      "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "tensor = torch.rand(1, 1, 1, 10)\n",
    "newTensor = tensor.squeeze()\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "print(\"--------\")\n",
    "print(newTensor)\n",
    "print(newTensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce99a94-6e3d-4ca9-a23f-23cd6bcdff8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4a62a-ef40-4ecf-861e-60c93f1ee8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e35cfb-4a81-4a06-9527-03df9fa9f624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4013dc-ca10-4f5d-b747-9017a6eb434a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
